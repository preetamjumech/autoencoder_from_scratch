{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFQUUy0v6SyVE1coKWfRuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/autoencoder_from_scratch/blob/main/Preetam_Saha_23_09_2022_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X13Hi-i2tKsg"
      },
      "outputs": [],
      "source": [
        "#add some amount of noise , auto encoder will remove the noise\n",
        "#pca, svd for dimensional reduction linear in nature\n",
        "#in autoencoder, one encoder one decoding layer, in images, features are highly correlated, extract features which are non linear in nature\n",
        "#to retain key features in input space, lesser no of dimension that is good thing,\n",
        "#in training we are interested in encoder and decoder bothe, in inference  \n",
        "#in inference either we are interested in encoder or interested in decoder, not both, (denoising the images - encoder and decoder both are required)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt"
      ],
      "metadata": {
        "id": "53ltFiRguDVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first dnn based autoencoder, then we will create convolutional based autocoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "Q6UtSokiu304"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = torch.load(\"training.pt\"), torch.load(\"test.pt\")"
      ],
      "metadata": {
        "id": "vitfrKN9vzgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test,y_test) = (train, test)"
      ],
      "metadata": {
        "id": "CVXA-B9Yv70i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1,28*28)/255.\n",
        "x_test = x_test.reshape(-1,28*28)/255."
      ],
      "metadata": {
        "id": "kZbBIbQdwRmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = nn.Sequential(nn.Linear(in_features = 28*28, out_features= 256), # if im using linear activation , will be similiar to pca, we will use non-linear here\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=256,out_features=128),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=128,out_features=64),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=64,out_features=16)) #starting from 764, ending with 16, significant number of reduction of columns"
      ],
      "metadata": {
        "id": "itYA0p7bwo1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = nn.Sequential(nn.Linear(in_features = 16, out_features= 64), \n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=64,out_features=128),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=128,out_features=256),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(in_features=256,out_features=28*28)) #rate at which dimension was reduced , same rate to increase"
      ],
      "metadata": {
        "id": "Zc-bKDb1y0ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = nn.Sequential(encoder,decoder) # we dont use batchnormalization, dropput in auto encoder, obj is to reach higher to lower dimension "
      ],
      "metadata": {
        "id": "0_uJJ-wrzipf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obj is to recreate the image, choice of loss function = RMSe, its a construction loss, we want to map this loss individual pixels.\n",
        "train_loader = DataLoader(TensorDataset(x_train.float(),y_train),\n",
        "                          batch_size=64,shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(x_test.float(),y_test),\n",
        "                          batch_size=64,shuffle=False)"
      ],
      "metadata": {
        "id": "T-muduQjznWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "eg6xJs2707Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "autoencoder = autoencoder.to(device)\n",
        "opt = Adam(autoencoder.parameters())"
      ],
      "metadata": {
        "id": "iBDMK2w_1IXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#good practice to use a function instead of for loop\n",
        "def train(model,train_loader,val_loader,opt,epoch):\n",
        "  training_loss = 0.0\n",
        "  val_loss = 0.0\n",
        "\n",
        "#training portion\n",
        "  for batch, _ in train_loader: #not building any classification model, so input = ouput\n",
        "    batch = batch.to(device)\n",
        "    target = batch.to(device)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    train_output = model(batch)\n",
        "    train_loss = F.mse_loss(train_output,target)\n",
        "    train_loss.backward()\n",
        "    opt.step()\n",
        "    training_loss += train_loss.item()\n",
        "\n",
        "  if (epoch+1) %  10 ==0:\n",
        "    print(f\"Train loss: {training_loss}\")\n",
        "\n",
        "#validation part\n",
        "  with torch.no_grad():\n",
        "    for val_batch, _ in val_loader:\n",
        "      val_batch = val_batch.to(device)\n",
        "      val_target = val_batch.to(device)\n",
        "      \n",
        "      val_output = model(val_batch)\n",
        "      loss_val = F.mse_loss(val_output,val_target)\n",
        "      val_loss += loss_val.item()\n",
        "\n",
        "  \n",
        "  if (epoch+1) %  10 ==0:\n",
        "    print(f\"Train loss: {training_loss} and Val loss: {val_loss}\")\n",
        "\n",
        "  return (training_loss, val_loss)"
      ],
      "metadata": {
        "id": "xSKtAdSa1b5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  losses.append(train(autoencoder,train_loader=train_loader, val_loader=val_loader,\n",
        "                      opt=opt,epoch=epoch)) #epoch only for prininting, nothinh to do with training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYm2gEyC62Eb",
        "outputId": "0fe85a6c-d4b0-465e-8c60-53c9d7a4f9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 13.785349544137716\n",
            "Train loss: 13.785349544137716 and Val loss: 2.257694525644183\n",
            "Train loss: 11.91914537269622\n",
            "Train loss: 11.91914537269622 and Val loss: 1.9960096143186092\n",
            "Train loss: 11.180045291781425\n",
            "Train loss: 11.180045291781425 and Val loss: 1.8780414666980505\n",
            "Train loss: 10.738649767823517\n",
            "Train loss: 10.738649767823517 and Val loss: 1.8042737180367112\n",
            "Train loss: 10.456409282051027\n",
            "Train loss: 10.456409282051027 and Val loss: 1.785088049247861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 20\n",
        "img_arbit = x_test[idx]"
      ],
      "metadata": {
        "id": "eqAvk7d5-TSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_arbit.numpy().reshape(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "i1BtecnJ-lns",
        "outputId": "a36cc48c-6e45-4fb0-fd9f-4809685ae521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9d001f4490>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here also kind of embeeding not exactly like text\n",
        "input_data = img_arbit.reshape(1,-1).float().to(device)"
      ],
      "metadata": {
        "id": "pPZIG6aO-0P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_encoder = encoder(input_data)\n",
        "output_encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdcd7Tpx_OcT",
        "outputId": "a22ec804-d7da-4792-c71a-8166a7487131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0967,  1.4813,  0.4142,  0.3497, -0.1225,  0.6258,  0.8599, -0.5653,\n",
              "         -0.8530, -0.0474, -0.2781,  0.6254,  0.2057,  0.1826,  0.0877,  0.7132]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_decoder=decoder(output_encoder).detach().cpu().numpy().reshape(28,28)"
      ],
      "metadata": {
        "id": "W5Z6RHM8BUOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(output_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "k6pGJJqa_-Ss",
        "outputId": "675288d4-7dd3-44ba-e6cb-94bb323e6168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9d001094d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is vanila autoencoders  , another one is VAE"
      ],
      "metadata": {
        "id": "tPL17uN8AEyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}